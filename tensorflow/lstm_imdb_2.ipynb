{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0d6800fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import LSTM, Dense, InputLayer, Embedding, Flatten\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.datasets import imdb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ee0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_distinct_words = 5000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_distinct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "651c2bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04d01ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 189)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0]), len(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43cf45e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a81f69c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [len(i) for i in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73e9e09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2494"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f02b3e",
   "metadata": {},
   "source": [
    "#### pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04c8bd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [[1], [2, 3], [4, 5, 6]]\n",
    "tf.keras.preprocessing.sequence.pad_sequences(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0763e675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1,  1],\n",
       "       [-1,  2,  3],\n",
       "       [ 4,  5,  6]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [[1], [2, 3], [4, 5, 6]]\n",
    "tf.keras.preprocessing.sequence.pad_sequences(sequence, value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "303ccc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2, -2, -2, -2,  1],\n",
       "       [-2, -2, -2,  2,  3],\n",
       "       [-2, -2,  4,  5,  6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [[1], [2, 3], [4, 5, 6]]\n",
    "tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=5, value=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45bc3cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2,  1],\n",
       "       [ 2,  3],\n",
       "       [ 5,  6]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [[1], [2, 3], [4, 5, 6]]\n",
    "tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=2, value=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbec688",
   "metadata": {},
   "source": [
    "#### pad the x_train and x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23289769",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_padded = pad_sequences(x_train, maxlen=1000, value=0)\n",
    "x_test_padded = pad_sequences(x_test, maxlen=1000, value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93b13bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([InputLayer(input_shape=(1000, )),\n",
    "                   Embedding(input_dim=num_distinct_words, output_dim=16),\n",
    "                   LSTM(16),\n",
    "                   Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8387cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac1a2f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 221s 281ms/step - loss: 0.4135 - acc: 0.8279\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 227s 291ms/step - loss: 0.2685 - acc: 0.8963\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 228s 291ms/step - loss: 0.2302 - acc: 0.9133\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 228s 292ms/step - loss: 0.2027 - acc: 0.9232\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 227s 290ms/step - loss: 0.4020 - acc: 0.8136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227328aa700>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_padded, y_train, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39041bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 210s 266ms/step - loss: 0.4221 - acc: 0.8009\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 226s 289ms/step - loss: 0.2861 - acc: 0.8880\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 227s 290ms/step - loss: 0.2379 - acc: 0.9078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22750f72790>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "                   Embedding(input_dim=num_distinct_words, output_dim=16, input_length=1000), #output will be (batch_size, 1000, 16)\n",
    "                   LSTM(16, return_sequences=False), \n",
    "                   Dense(1, activation='sigmoid')])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics='acc')\n",
    "model.fit(x_train_padded, y_train, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "786727c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 211s 268ms/step - loss: 0.3671 - acc: 0.8277\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 226s 289ms/step - loss: 0.2343 - acc: 0.9065\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 227s 291ms/step - loss: 0.1894 - acc: 0.9256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227598fb8e0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "                   Embedding(input_dim=num_distinct_words, output_dim=16, input_length=1000), #output will be (batch_size, 1000, 16)\n",
    "                   LSTM(16, return_sequences=True), # This will return shape: (Batch_size, 1000, 16)\n",
    "                    Flatten(),\n",
    "                   Dense(1, activation='sigmoid')])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics='acc')\n",
    "model.fit(x_train_padded, y_train, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d6fec03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 9, 2, 3],\n",
       "       [5, 1, 7, 6],\n",
       "       [8, 4, 5, 6]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(low=0, high=10, size=(3, 4))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dc2afc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 5)\n",
      "(3, 6)\n"
     ]
    }
   ],
   "source": [
    "x_embed = Embedding(input_dim=10, output_dim=5, input_length=4)(x) # (batch_size, 4, 5)\n",
    "print(x_embed.shape)\n",
    "lstm_output = LSTM(6, return_sequences=False)(x_embed)\n",
    "print(lstm_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3bda0e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 5)\n",
      "(3, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(low=0, high=10, size=(3, 4))\n",
    "x_embed = Embedding(input_dim=10, output_dim=5, input_length=4)(x) # (batch_size, 4, 5)\n",
    "print(x_embed.shape)\n",
    "lstm_output = LSTM(6, return_sequences=True)(x_embed)\n",
    "print(lstm_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f19fd1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
