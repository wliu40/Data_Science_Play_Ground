{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8db4a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0821b9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weiliu\\Anaconda3\\envs\\dl\\lib\\site-packages\\gdown\\cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=108jAePKK4R3BVYBbYJZ32JWUwxeMg20K\n",
      "To: C:\\Users\\weiliu\\work\\tensorflow\\sonnets.txt\n",
      "\n",
      "  0%|          | 0.00/93.6k [00:00<?, ?B/s]\n",
      "100%|##########| 93.6k/93.6k [00:00<00:00, 370kB/s]\n",
      "100%|##########| 93.6k/93.6k [00:00<00:00, 369kB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sonnets.txt\n",
    "!gdown --id 108jAePKK4R3BVYBbYJZ32JWUwxeMg20K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fdcbab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2159 lines of sonnets\n",
      "\n",
      "The first 5 lines look like this:\n",
      "\n",
      "from fairest creatures we desire increase,\n",
      "that thereby beauty's rose might never die,\n",
      "but as the riper should by time decease,\n",
      "his tender heir might bear his memory:\n",
      "but thou, contracted to thine own bright eyes,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define path for file with sonnets\n",
    "SONNETS_FILE = './sonnets.txt'\n",
    "\n",
    "# Read the data\n",
    "with open('./sonnets.txt') as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Convert to lower case and save as a list\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "print(f\"There are {len(corpus)} lines of sonnets\\n\")\n",
    "print(f\"The first 5 lines look like this:\\n\")\n",
    "for i in range(5):\n",
    "    print(corpus[i])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2af85ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a97764e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from fairest creatures we desire increase,'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68575061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [58],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [17],\n",
       " [6],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [17],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [6],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [6],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [17],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be6b290e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[34, 417, 877, 166, 213, 517]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer.texts_to_sequences([corpus[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "062ccdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34, 417, 877, 166, 213, 517]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([corpus[0]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0df00fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now complete the n_gram_seqs function below. \n",
    "# This function receives the fitted tokenizer and the corpus (which is a list of strings) \n",
    "# and should return a list containing the n_gram sequences for each line in the corpus:\n",
    "\n",
    "# GRADED FUNCTION: n_gram_seqs\n",
    "def n_gram_seqs(corpus, tokenizer):\n",
    "    input_sequences = []\n",
    "    \n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            # Generate subphrase\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            # Append subphrase to input_sequences list\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e88e269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram sequences for first example look like this:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[34, 417],\n",
       " [34, 417, 877],\n",
       " [34, 417, 877, 166],\n",
       " [34, 417, 877, 166, 213],\n",
       " [34, 417, 877, 166, 213, 517]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Test your function with one example\n",
    "first_example_sequence = n_gram_seqs([corpus[0]], tokenizer)\n",
    "\n",
    "print(\"n_gram sequences for first example look like this:\\n\")\n",
    "first_example_sequence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fd89147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram sequences for next 3 examples look like this:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[8, 878],\n",
       " [8, 878, 134],\n",
       " [8, 878, 134, 351],\n",
       " [8, 878, 134, 351, 102],\n",
       " [8, 878, 134, 351, 102, 156],\n",
       " [8, 878, 134, 351, 102, 156, 199],\n",
       " [16, 22],\n",
       " [16, 22, 2],\n",
       " [16, 22, 2, 879],\n",
       " [16, 22, 2, 879, 61],\n",
       " [16, 22, 2, 879, 61, 30],\n",
       " [16, 22, 2, 879, 61, 30, 48],\n",
       " [16, 22, 2, 879, 61, 30, 48, 634],\n",
       " [25, 311],\n",
       " [25, 311, 635],\n",
       " [25, 311, 635, 102],\n",
       " [25, 311, 635, 102, 200],\n",
       " [25, 311, 635, 102, 200, 25],\n",
       " [25, 311, 635, 102, 200, 25, 278]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Test your function with a bigger corpus\n",
    "next_3_examples_sequence = n_gram_seqs(corpus[1:4], tokenizer)\n",
    "\n",
    "print(\"n_gram sequences for next 3 examples look like this:\\n\")\n",
    "next_3_examples_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6af0952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_grams of input_sequences have length: 15462\n",
      "maximum length of sequences is: 11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply the n_gram_seqs transformation to the whole corpus\n",
    "input_sequences = n_gram_seqs(corpus, tokenizer)\n",
    "\n",
    "# Save max length \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "\n",
    "print(f\"n_grams of input_sequences have length: {len(input_sequences)}\")\n",
    "print(f\"maximum length of sequences is: {max_sequence_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0db26ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GRADED FUNCTION: pad_seqs\n",
    "def pad_seqs(input_sequences, maxlen):\n",
    "    ### START CODE HERE\n",
    "    padded_sequences = pad_sequences(input_sequences, maxlen=maxlen, padding='pre')\n",
    "    \n",
    "    return padded_sequences\n",
    "    ### END CODE HERE\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e78c7fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,  34, 417],\n",
       "       [  0,   0,  34, 417, 877],\n",
       "       [  0,  34, 417, 877, 166],\n",
       "       [ 34, 417, 877, 166, 213],\n",
       "       [417, 877, 166, 213, 517]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Test your function with the n_grams_seq of the first example\n",
    "first_padded_seq = pad_seqs(first_example_sequence, len(first_example_sequence))\n",
    "first_padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f78cc1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   8, 878],\n",
       "       [  0,   0,   0,   0,   0,   8, 878, 134],\n",
       "       [  0,   0,   0,   0,   8, 878, 134, 351],\n",
       "       [  0,   0,   0,   8, 878, 134, 351, 102],\n",
       "       [  0,   0,   8, 878, 134, 351, 102, 156],\n",
       "       [  0,   8, 878, 134, 351, 102, 156, 199],\n",
       "       [  0,   0,   0,   0,   0,   0,  16,  22],\n",
       "       [  0,   0,   0,   0,   0,  16,  22,   2],\n",
       "       [  0,   0,   0,   0,  16,  22,   2, 879],\n",
       "       [  0,   0,   0,  16,  22,   2, 879,  61],\n",
       "       [  0,   0,  16,  22,   2, 879,  61,  30],\n",
       "       [  0,  16,  22,   2, 879,  61,  30,  48],\n",
       "       [ 16,  22,   2, 879,  61,  30,  48, 634],\n",
       "       [  0,   0,   0,   0,   0,   0,  25, 311],\n",
       "       [  0,   0,   0,   0,   0,  25, 311, 635],\n",
       "       [  0,   0,   0,   0,  25, 311, 635, 102],\n",
       "       [  0,   0,   0,  25, 311, 635, 102, 200],\n",
       "       [  0,   0,  25, 311, 635, 102, 200,  25],\n",
       "       [  0,  25, 311, 635, 102, 200,  25, 278]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Test your function with the n_grams_seq of the next 3 examples\n",
    "next_3_padded_seq = pad_seqs(next_3_examples_sequence, max([len(s) for s in next_3_examples_sequence]))\n",
    "next_3_padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c34f39ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded corpus has shape: (15462, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Pad the whole corpus\n",
    "input_sequences = pad_seqs(input_sequences, max_sequence_len)\n",
    "\n",
    "print(f\"padded corpus has shape: {input_sequences.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fa9c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GRADED FUNCTION: features_and_labels\n",
    "def features_and_labels(input_sequences, total_words):\n",
    "    ### START CODE HERE\n",
    "    features = input_sequences[:,:-1]\n",
    "    labels = input_sequences[:,-1]\n",
    "    one_hot_labels = to_categorical(labels, num_classes=total_words)\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return features, one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69d0dc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical([[1],[2]], num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c0a9271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels have shape: (5, 3211)\n",
      "\n",
      "features look like this:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,  34],\n",
       "       [  0,   0,  34, 417],\n",
       "       [  0,  34, 417, 877],\n",
       "       [ 34, 417, 877, 166],\n",
       "       [417, 877, 166, 213]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Test your function with the padded n_grams_seq of the first example\n",
    "first_features, first_labels = features_and_labels(first_padded_seq, total_words)\n",
    "\n",
    "print(f\"labels have shape: {first_labels.shape}\")\n",
    "print(\"\\nfeatures look like this:\\n\")\n",
    "first_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a4c2973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_labels.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a27ca26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features have shape: (15462, 10)\n",
      "labels have shape: (15462, 3211)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split the whole corpus\n",
    "features, labels = features_and_labels(input_sequences, total_words)\n",
    "\n",
    "print(f\"features have shape: {features.shape}\")\n",
    "print(f\"labels have shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ffc4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GRADED FUNCTION: create_model\n",
    "def create_model(total_words, max_sequence_len):\n",
    "    \n",
    "    model = Sequential()\n",
    "    ### START CODE HERE\n",
    "    model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "    model.add(Bidirectional(LSTM(150)))\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    ### END CODE HERE\n",
    "\n",
    "    return model\n",
    "     \n",
    "    \n",
    "    \"\"\"\n",
    "    In Keras, when an LSTM(return_sequences = True) layer is followed by Dense() layer, \n",
    "    this is equivalent to LSTM(return_sequences = True) followed by TimeDistributed(Dense()). \n",
    "    When return_sequences is set to False, Dense is applied to the last time step only\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98334752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "484/484 [==============================] - 8s 11ms/step - loss: 6.8762 - accuracy: 0.0218\n",
      "Epoch 2/50\n",
      "484/484 [==============================] - 11s 23ms/step - loss: 6.4229 - accuracy: 0.0322\n",
      "Epoch 3/50\n",
      "484/484 [==============================] - 7s 14ms/step - loss: 6.1744 - accuracy: 0.0419\n",
      "Epoch 4/50\n",
      "484/484 [==============================] - 6s 12ms/step - loss: 5.8884 - accuracy: 0.0550\n",
      "Epoch 5/50\n",
      "484/484 [==============================] - 14s 28ms/step - loss: 5.5712 - accuracy: 0.0667\n",
      "Epoch 6/50\n",
      "484/484 [==============================] - 6s 12ms/step - loss: 5.1968 - accuracy: 0.0824\n",
      "Epoch 7/50\n",
      "484/484 [==============================] - 11s 23ms/step - loss: 4.7874 - accuracy: 0.1073\n",
      "Epoch 8/50\n",
      "484/484 [==============================] - 60s 125ms/step - loss: 4.3601 - accuracy: 0.1444\n",
      "Epoch 9/50\n",
      "484/484 [==============================] - 29s 60ms/step - loss: 3.9352 - accuracy: 0.2011\n",
      "Epoch 10/50\n",
      "484/484 [==============================] - 20s 41ms/step - loss: 3.5316 - accuracy: 0.2648\n",
      "Epoch 11/50\n",
      "484/484 [==============================] - 13s 26ms/step - loss: 3.1633 - accuracy: 0.3364\n",
      "Epoch 12/50\n",
      "484/484 [==============================] - 12s 24ms/step - loss: 2.8365 - accuracy: 0.4018\n",
      "Epoch 13/50\n",
      "484/484 [==============================] - 11s 22ms/step - loss: 2.5533 - accuracy: 0.4525\n",
      "Epoch 14/50\n",
      "484/484 [==============================] - 10s 21ms/step - loss: 2.3063 - accuracy: 0.5070\n",
      "Epoch 15/50\n",
      "484/484 [==============================] - 10s 21ms/step - loss: 2.0863 - accuracy: 0.5541\n",
      "Epoch 16/50\n",
      "484/484 [==============================] - 15s 31ms/step - loss: 1.8886 - accuracy: 0.5964\n",
      "Epoch 17/50\n",
      "484/484 [==============================] - 18s 36ms/step - loss: 1.7190 - accuracy: 0.6351\n",
      "Epoch 18/50\n",
      "484/484 [==============================] - 17s 36ms/step - loss: 1.5603 - accuracy: 0.6729\n",
      "Epoch 19/50\n",
      "484/484 [==============================] - 15s 31ms/step - loss: 1.4297 - accuracy: 0.7009\n",
      "Epoch 20/50\n",
      "484/484 [==============================] - 16s 34ms/step - loss: 1.3090 - accuracy: 0.7281\n",
      "Epoch 21/50\n",
      "484/484 [==============================] - 17s 36ms/step - loss: 1.2004 - accuracy: 0.7522\n",
      "Epoch 22/50\n",
      "484/484 [==============================] - 15s 30ms/step - loss: 1.1130 - accuracy: 0.7690\n",
      "Epoch 23/50\n",
      "484/484 [==============================] - 17s 34ms/step - loss: 1.0320 - accuracy: 0.7857\n",
      "Epoch 24/50\n",
      "484/484 [==============================] - 17s 35ms/step - loss: 0.9680 - accuracy: 0.7975\n",
      "Epoch 25/50\n",
      "484/484 [==============================] - 10s 21ms/step - loss: 0.9058 - accuracy: 0.8071\n",
      "Epoch 26/50\n",
      "484/484 [==============================] - 16s 33ms/step - loss: 0.8481 - accuracy: 0.8183\n",
      "Epoch 27/50\n",
      "484/484 [==============================] - 11s 22ms/step - loss: 0.8115 - accuracy: 0.8229\n",
      "Epoch 28/50\n",
      "484/484 [==============================] - 11s 22ms/step - loss: 0.7799 - accuracy: 0.8293\n",
      "Epoch 29/50\n",
      "484/484 [==============================] - 16s 34ms/step - loss: 0.7456 - accuracy: 0.8314\n",
      "Epoch 30/50\n",
      "484/484 [==============================] - 16s 33ms/step - loss: 0.7227 - accuracy: 0.8349\n",
      "Epoch 31/50\n",
      "484/484 [==============================] - 15s 30ms/step - loss: 0.6983 - accuracy: 0.8387\n",
      "Epoch 32/50\n",
      "484/484 [==============================] - 15s 32ms/step - loss: 0.6775 - accuracy: 0.8425\n",
      "Epoch 33/50\n",
      "484/484 [==============================] - 10s 21ms/step - loss: 0.6687 - accuracy: 0.8406\n",
      "Epoch 34/50\n",
      "484/484 [==============================] - 16s 33ms/step - loss: 0.6494 - accuracy: 0.8452\n",
      "Epoch 35/50\n",
      "484/484 [==============================] - 16s 33ms/step - loss: 0.6370 - accuracy: 0.8466\n",
      "Epoch 36/50\n",
      "484/484 [==============================] - 10s 21ms/step - loss: 0.6240 - accuracy: 0.8463\n",
      "Epoch 37/50\n",
      "484/484 [==============================] - 14s 29ms/step - loss: 0.6288 - accuracy: 0.8449\n",
      "Epoch 38/50\n",
      "484/484 [==============================] - 10s 20ms/step - loss: 0.6189 - accuracy: 0.8455\n",
      "Epoch 39/50\n",
      "484/484 [==============================] - 16s 32ms/step - loss: 0.6052 - accuracy: 0.8470\n",
      "Epoch 40/50\n",
      "484/484 [==============================] - 16s 32ms/step - loss: 0.5999 - accuracy: 0.8474\n",
      "Epoch 41/50\n",
      "484/484 [==============================] - 14s 30ms/step - loss: 0.5940 - accuracy: 0.8486\n",
      "Epoch 42/50\n",
      "484/484 [==============================] - 16s 32ms/step - loss: 0.5868 - accuracy: 0.8508\n",
      "Epoch 43/50\n",
      "484/484 [==============================] - 16s 32ms/step - loss: 0.5879 - accuracy: 0.8481\n",
      "Epoch 44/50\n",
      "484/484 [==============================] - 10s 21ms/step - loss: 0.5818 - accuracy: 0.8496\n",
      "Epoch 45/50\n",
      "484/484 [==============================] - 16s 33ms/step - loss: 0.5800 - accuracy: 0.8487\n",
      "Epoch 46/50\n",
      "484/484 [==============================] - 16s 32ms/step - loss: 0.5768 - accuracy: 0.8485\n",
      "Epoch 47/50\n",
      "484/484 [==============================] - 17s 35ms/step - loss: 0.5760 - accuracy: 0.8490\n",
      "Epoch 48/50\n",
      "484/484 [==============================] - 11s 23ms/step - loss: 0.5706 - accuracy: 0.8490\n",
      "Epoch 49/50\n",
      "484/484 [==============================] - 18s 36ms/step - loss: 0.5664 - accuracy: 0.8487\n",
      "Epoch 50/50\n",
      "484/484 [==============================] - 17s 35ms/step - loss: 0.5670 - accuracy: 0.8479\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the untrained model\n",
    "model = create_model(total_words, max_sequence_len)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(features, labels, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "808cffaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help me Obi Wan Kenobi, you're my only hope my name is crown'd knowing and all in her part it doth dwell in comfort to thee blind blind bright bright bright rhyme bright now ' ' ' know ere thou bastard be old of all too green more express'd in me hold it green me blind none dearer fearing of know long die in me thy view grace heart knows his ' ' be on thee die not here doth give my friend still blind blind hate ' hate me thee thence thee thou art old strength of shame nor all away it done grace ' ' tillage to\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    # Convert the text into sequences\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    # Pad the sequences\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    # Get the probabilities of predicting a word\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    # Choose the next word based on the maximum probability\n",
    "    predicted = np.argmax(predicted, axis=-1).item()\n",
    "    # Get the actual word from the word index\n",
    "    output_word = tokenizer.index_word[predicted]\n",
    "    # Append to the current text\n",
    "    seed_text += \" \" + output_word\n",
    "\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30977a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
