{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be948028",
   "metadata": {},
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "Embedding(input_dims, output_dims, input_length)\n",
    "\n",
    "Embedding is to convert a matrix to higher dimension, each element in the original matrix will be converted to a <output_dims> size array.\n",
    "\n",
    "assume your input is (batch_size, input_length), the output shape will be (batch_size, input_length,  output_dims)\n",
    "\n",
    "input_dims is the np.nunique(), that is how many unique elements in this matrix.\n",
    "output_dims is the embedding dimension.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4301c350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,) input shape\n",
      "tf.Tensor(\n",
      "[[ 0.0298583   0.04626484  0.01171456  0.0496533 ]\n",
      " [ 0.02824173 -0.00289433 -0.02393568  0.01701376]\n",
      " [ 0.0037143  -0.02745137  0.01740715  0.0195791 ]\n",
      " [ 0.0298583   0.04626484  0.01171456  0.0496533 ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.04209925 -0.04736764 -0.01638738 -0.03430145]\n",
      " [ 0.04235135  0.01985892  0.03813492  0.01290094]\n",
      " [-0.00801114  0.0300547   0.02101244  0.03156258]\n",
      " [ 0.04209925 -0.04736764 -0.01638738 -0.03430145]], shape=(4, 4), dtype=float32)\n",
      "(4, 4)\n",
      "###################\n",
      "(2, 3) input shape\n",
      "(2, 3, 4)\n",
      "###################\n",
      "(2, 2, 3) input shape\n",
      "(2, 2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "import numpy as np\n",
    "\n",
    "x = [1,2,4,1]\n",
    "\n",
    "print(np.asarray(x).shape, 'input shape')\n",
    "print(Embedding(input_dim=5, output_dim=4, input_length=None)(np.asarray(x)))\n",
    "print(Embedding(input_dim=5, output_dim=4, input_length=4)(np.asarray(x)))\n",
    "print(Embedding(input_dim=5, output_dim=4, input_length=3)(np.asarray(x)).shape)\n",
    "\n",
    "print('###################')\n",
    "\n",
    "x = [[1,2,4], [3,5,6]]\n",
    "\n",
    "print(np.asarray(x).shape, 'input shape')\n",
    "\n",
    "print(Embedding(input_dim=7, output_dim=4, input_length=None)(np.asarray(x)).shape)\n",
    "\n",
    "print('###################')\n",
    "x = [[[1,2,4], [3,5,6]], [[1,2,4], [3,5,6]]]\n",
    "print(np.asarray(x).shape, 'input shape')\n",
    "\n",
    "print(Embedding(input_dim=7, output_dim=4, input_length=3)(np.asarray(x)).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b63726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27b22b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_data = [\n",
    "  \"I enjoy coffee.\",\n",
    "  \"I enjoy tea.\",\n",
    "  \"I dislike milk.\",\n",
    "  \"I am going to the supermarket later this morning for some coffee.\"\n",
    "]\n",
    "\n",
    "test_data = [\n",
    "  \"Enjoy coffee this morning.\",\n",
    "  \"I enjoy going to the supermarket.\",\n",
    "  \"Want some milk for your coffee?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1314436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 1000\n",
    "oov_token = '<UNK>'\n",
    "pad_type = 'post'\n",
    "trunc_type = 'post'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89ea592e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<UNK>': 1, 'i': 2, 'enjoy': 3, 'coffee': 4, 'tea': 5, 'dislike': 6, 'milk': 7, 'am': 8, 'going': 9, 'to': 10, 'the': 11, 'supermarket': 12, 'later': 13, 'this': 14, 'morning': 15, 'for': 16, 'some': 17}\n"
     ]
    }
   ],
   "source": [
    "# Tokenize our training data\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(train_data)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "num_words: the maximum number of words to keep, based on word frequency. \n",
    "Only the most common num_words-1 words will be kept.\n",
    "\n",
    "filters: a string where each element is a character that will be filtered from the texts.\n",
    "The default is all punctuation, plus tabs and line breaks, minus the ' character.\n",
    "\n",
    "lower: boolean. Whether to convert the texts to lowercase.\n",
    "\n",
    "split: str. Separator for word splitting.\n",
    "\n",
    "char_level: if True, every character will be treated as a token.\n",
    "\n",
    "oov_token: if given, it will be added to word_index and used to replace out-of-vocabulary words during text_to_sequence calls\n",
    "\n",
    "analyzer: function. Custom analyzer to split the text. The default analyzer is text_to_word_sequence\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Get our training data word index\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2547e528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4], [2, 3, 5], [2, 6, 7], [2, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 4]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode training data sentences into sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data)\n",
    "train_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f26f7a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4, 1], [1, 1, 1, 1]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_data = [\"I enjoy coffee too.\", \"Wait a minute! Woodpecker\"]\n",
    "other_sequence = tokenizer.texts_to_sequences(other_data)\n",
    "other_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30909f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word index:\n",
      " {'<UNK>': 1, 'i': 2, 'enjoy': 3, 'coffee': 4, 'tea': 5, 'dislike': 6, 'milk': 7, 'am': 8, 'going': 9, 'to': 10, 'the': 11, 'supermarket': 12, 'later': 13, 'this': 14, 'morning': 15, 'for': 16, 'some': 17}\n",
      "\n",
      "Training sequences:\n",
      " [[2, 3, 4], [2, 3, 5], [2, 6, 7], [2, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 4]]\n",
      "\n",
      "Padded training sequences:\n",
      " [[ 2  3  4  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  3  5  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  6  7  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  8  9 10 11 12 13 14 15 16 17  4]]\n",
      "\n",
      "Padded training shape: (4, 12)\n",
      "Training sequences data type: <class 'list'>\n",
      "Padded Training sequences data type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Get max training sequence length\n",
    "maxlen = max([len(x) for x in train_sequences])\n",
    "\n",
    "# Pad the training sequences\n",
    "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n",
    "\n",
    "# Output the results of our work\n",
    "print(\"Word index:\\n\", word_index)\n",
    "print(\"\\nTraining sequences:\\n\", train_sequences)\n",
    "print(\"\\nPadded training sequences:\\n\", train_padded)\n",
    "print(\"\\nPadded training shape:\", train_padded.shape)\n",
    "print(\"Training sequences data type:\", type(train_sequences))\n",
    "print(\"Padded Training sequences data type:\", type(train_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdb28b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fda06e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10, 64)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(input_dim=1000, output_dim=64, input_length=10))\n",
    "# The model will take as input an integer matrix of size (batch,\n",
    "# input_length), and the largest integer (i.e. word index) in the input\n",
    "# should be no larger than 999 (vocabulary size).\n",
    "# Now model.output_shape is (None, 10, 64), where `None` is the batch\n",
    "# dimension.\n",
    "input_array = np.random.randint(1000, size=(32, 10))\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "print(output_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57ad5514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x22732ce3d60>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding(input_dim=100, output_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90188c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  3,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  6,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,  4]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "012549ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 12, 3), dtype=float32, numpy=\n",
       "array([[[ 0.04241655, -0.04044966,  0.0050756 ],\n",
       "        [ 0.03242183,  0.01625469, -0.03169619],\n",
       "        [-0.01406216, -0.0284556 , -0.01600685],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824]],\n",
       "\n",
       "       [[ 0.04241655, -0.04044966,  0.0050756 ],\n",
       "        [ 0.03242183,  0.01625469, -0.03169619],\n",
       "        [-0.01698017,  0.01756532, -0.01632979],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824]],\n",
       "\n",
       "       [[ 0.04241655, -0.04044966,  0.0050756 ],\n",
       "        [ 0.03614232,  0.02778044, -0.01482513],\n",
       "        [-0.01102179,  0.03071158, -0.03697109],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824],\n",
       "        [-0.00468552, -0.04007109,  0.01506824]],\n",
       "\n",
       "       [[ 0.04241655, -0.04044966,  0.0050756 ],\n",
       "        [ 0.00636407, -0.01432618, -0.0441831 ],\n",
       "        [ 0.02216581,  0.03405634, -0.00654586],\n",
       "        [-0.04667259, -0.01971695, -0.02313992],\n",
       "        [-0.01735026, -0.02911183, -0.01960739],\n",
       "        [ 0.01284716, -0.0429577 , -0.01736198],\n",
       "        [ 0.00827191, -0.04999726, -0.04373938],\n",
       "        [ 0.01122193,  0.02781175,  0.00654061],\n",
       "        [ 0.03347195, -0.04809834, -0.01149355],\n",
       "        [-0.0346015 , -0.04761947,  0.03984592],\n",
       "        [-0.03858699, -0.02626395,  0.04023266],\n",
       "        [-0.01406216, -0.0284556 , -0.01600685]]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding(input_dim=18, output_dim=3)(train_padded) # since the largeset number is 17, so, the input_dim is 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9793caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "tf.Tensor(\n",
      "[[[-0.01400142  0.43735096 -0.7691392  -0.9390922 ]\n",
      "  [-0.6324583  -0.01914891 -0.89955014  0.33869278]\n",
      "  [-1.9478154  -0.6656561  -0.19483899 -1.1875447 ]]\n",
      "\n",
      " [[-0.5147505   0.4984039   0.906299    0.08101185]\n",
      "  [-1.0919018   0.7116297   0.91138214 -1.2478153 ]\n",
      "  [ 1.5654184   0.01883395 -0.8530751   0.9618612 ]]], shape=(2, 3, 4), dtype=float32) \n",
      "\n",
      " [[[5 5 1 5]\n",
      "  [1 5 0 4]\n",
      "  [2 8 8 7]]\n",
      "\n",
      " [[0 1 5 3]\n",
      "  [2 7 5 7]\n",
      "  [6 7 8 8]]]\n"
     ]
    }
   ],
   "source": [
    "input_shape = (2, 3, 4)\n",
    "x1 = tf.random.normal(input_shape)\n",
    "x2 = np.random.randint(low=0, high=10, size=(2,3, 4))\n",
    "\n",
    "print(x1, '\\n\\n', x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f606ffe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5, 5, 1, 5],\n",
       "        [1, 5, 0, 4],\n",
       "        [2, 8, 8, 7]],\n",
       "\n",
       "       [[0, 1, 5, 3],\n",
       "        [2, 7, 5, 7],\n",
       "        [6, 7, 8, 8]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ff8fa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "[[[5 5 1 5]\n",
      "  [1 5 0 4]\n",
      "  [2 8 8 7]]\n",
      "\n",
      " [[0 1 5 3]\n",
      "  [2 7 5 7]\n",
      "  [6 7 8 8]]] tf.Tensor(\n",
      "[[2 6 3 5]\n",
      " [2 5 6 6]], shape=(2, 4), dtype=int32)\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "y = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "print(y.shape)\n",
    "\n",
    "print(x2, y)\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7ef4d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5., 5., 1., 5.],\n",
       "        [1., 5., 0., 4.],\n",
       "        [2., 8., 8., 7.]],\n",
       "\n",
       "       [[0., 1., 5., 3.],\n",
       "        [2., 7., 5., 7.],\n",
       "        [6., 7., 8., 8.]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65a6c744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "[[[5 5 1 5]\n",
      "  [1 5 0 4]\n",
      "  [2 8 8 7]]\n",
      "\n",
      " [[0 1 5 3]\n",
      "  [2 7 5 7]\n",
      "  [6 7 8 8]]] tf.Tensor(\n",
      "[[2.6666667 6.        3.        5.3333335]\n",
      " [2.6666667 5.        6.        6.       ]], shape=(2, 4), dtype=float32)\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "y = tf.keras.layers.GlobalAveragePooling1D()(x2.astype(float))\n",
    "print(y.shape)\n",
    "\n",
    "print(x2, y)\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60197981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "[[[7 7 8 6]\n",
      "  [5 8 2 3]\n",
      "  [2 3 1 3]]\n",
      "\n",
      " [[5 3 5 0]\n",
      "  [1 9 2 2]\n",
      "  [5 4 9 2]]] tf.Tensor(\n",
      "[[7.   4.5  2.25]\n",
      " [3.25 3.5  5.  ]], shape=(2, 3), dtype=float32)\n",
      "-----------------------\n",
      "(2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "y = tf.keras.layers.GlobalAveragePooling1D(data_format='channels_first')(x2.astype(float)) # the default is channels_last\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "print(x2, y)\n",
    "print(\"-----------------------\")\n",
    "print(x2.shape) \n",
    "# If data_format='channels_last': 3D tensor with shape: (batch_size, steps, features)\n",
    "# If data_format='channels_first': 3D tensor with shape: (batch_size, features, steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c96309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 5), dtype=float32, numpy=\n",
       "array([[-3.00862323e-02,  4.49339189e-02, -2.94989236e-02,\n",
       "         3.85195017e-06, -3.42002288e-02],\n",
       "       [-3.04150581e-03, -3.85608450e-02, -1.44257173e-02,\n",
       "        -1.82052031e-02, -2.26071123e-02],\n",
       "       [ 3.91150601e-02,  1.24029629e-02, -3.72429863e-02,\n",
       "         1.45435445e-02, -1.28936656e-02],\n",
       "       [ 3.91150601e-02,  1.24029629e-02, -3.72429863e-02,\n",
       "         1.45435445e-02, -1.28936656e-02],\n",
       "       [-3.04150581e-03, -3.85608450e-02, -1.44257173e-02,\n",
       "        -1.82052031e-02, -2.26071123e-02],\n",
       "       [-3.00862323e-02,  4.49339189e-02, -2.94989236e-02,\n",
       "         3.85195017e-06, -3.42002288e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "import tensorflow as tf\n",
    "x = [1,2,3,3,2,1]\n",
    "Embedding(input_dim=4, output_dim=5)(tf.constant(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb1db14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2], [3], [4], [5], [1], [1]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "x = list('abcda')\n",
    "#x = tf.convert_to_tensor(x)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=6, oov_token='<OOV>')\n",
    "\n",
    "tokenizer.fit_on_texts(x)\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "\n",
    "y = list('abcdfg')\n",
    "tokenizer.texts_to_sequences(y)\n",
    "\n",
    "#Embedding(input_dim=4, output_dim=5)(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
