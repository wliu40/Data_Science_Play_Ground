{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3409eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b1f8fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "additional_metrics = ['accuracy']\n",
    "batch_size = 128\n",
    "embedding_output_dims = 15\n",
    "loss_function = BinaryCrossentropy()\n",
    "max_sequence_length = 300\n",
    "num_distinct_words = 5000\n",
    "number_of_epochs = 5\n",
    "optimizer = Adam()\n",
    "validation_split = 0.20\n",
    "verbosity_mode = 1\n",
    "\n",
    "# Disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "679272a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_distinct_words)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88654419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 [1, 14, 22, 16] -> 1\n",
      "189 [1, 194, 1153, 194] -> 0\n",
      "141 [1, 14, 47, 8] -> 0\n",
      "550 [1, 4, 2, 2] -> 1\n",
      "147 [1, 249, 1323, 7] -> 0\n",
      "43 [1, 778, 128, 74] -> 0\n",
      "123 [1, 2, 365, 1234] -> 1\n",
      "562 [1, 4, 2, 716] -> 0\n",
      "233 [1, 43, 188, 46] -> 1\n",
      "130 [1, 14, 20, 47] -> 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(len(x_train[i]), x_train[i][:4],'->', y_train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94e18b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "# Pad all sequences\n",
    "padded_inputs = pad_sequences(x_train, maxlen=max_sequence_length, value = 0.0) # 0.0 because it corresponds with <PAD>\n",
    "padded_inputs_test = pad_sequences(x_test, maxlen=max_sequence_length, value = 0.0) # 0.0 because it corresponds with <PAD>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8abf7473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0], dtype=int64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0]), y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ddfb593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 15)           75000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10)                1040      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 76,051\n",
      "Trainable params: 76,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - ETA: 0s - loss: 0.6025 - accuracy: 0.6927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weiliu\\Anaconda3\\envs\\dl\\lib\\site-packages\\keras\\engine\\training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 12s 594us/sample - loss: 0.6025 - accuracy: 0.6927 - val_loss: 0.4644 - val_accuracy: 0.8196\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 12s 591us/sample - loss: 0.3938 - accuracy: 0.8528 - val_loss: 0.3493 - val_accuracy: 0.8648\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 12s 618us/sample - loss: 0.2947 - accuracy: 0.8923 - val_loss: 0.3488 - val_accuracy: 0.8592\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 13s 634us/sample - loss: 0.2484 - accuracy: 0.9105 - val_loss: 0.3295 - val_accuracy: 0.8702\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 13s 648us/sample - loss: 0.2143 - accuracy: 0.9273 - val_loss: 0.3651 - val_accuracy: 0.8636\n",
      "Test results - Loss: 0.35858763427734375 - Accuracy: 86.46399974822998%\n"
     ]
    }
   ],
   "source": [
    "# Define the Keras model\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_distinct_words, embedding_output_dims, input_length=max_sequence_length))\n",
    "model.add(LSTM(10))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=additional_metrics)\n",
    "\n",
    "# Give a summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(padded_inputs, y_train, batch_size=batch_size, epochs=number_of_epochs, verbose=verbosity_mode, validation_split=validation_split)\n",
    "\n",
    "# Test the model after training\n",
    "test_results = model.evaluate(padded_inputs_test, y_test, verbose=False)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {100*test_results[1]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4fe990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
