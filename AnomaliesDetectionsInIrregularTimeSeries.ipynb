{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6cb05f-77ab-4ed9-a8bc-81f751501994",
   "metadata": {},
   "source": [
    "#### detection of the surging of events in an irregular time series\n",
    "\n",
    "__Inter-event Time Analysis:__\n",
    "\n",
    "Calculates the time between consecutive events.\n",
    "Flags events where the inter-event time is significantly shorter than average.\n",
    "\n",
    "\n",
    "__Sliding Window Event Count:__\n",
    "\n",
    "Counts events within a sliding time window.\n",
    "Flags time points where the event count is significantly higher than average.\n",
    "\n",
    "\n",
    "__Kernel Density Estimation:__\n",
    "\n",
    "Uses KDE to estimate the density of events over time.\n",
    "Flags events in regions of unusually high density."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce25d5b-3366-4213-9d56-ef05dc9fb8de",
   "metadata": {},
   "source": [
    "__Inter-event Time Analysis:__\n",
    "\n",
    "    WITH ordered_events AS (\n",
    "      SELECT \n",
    "        timestamp,\n",
    "        LAG(timestamp) OVER (ORDER BY timestamp) AS prev_timestamp\n",
    "      FROM events\n",
    "    ),\n",
    "    inter_event_times AS (\n",
    "      SELECT \n",
    "        timestamp,\n",
    "        EXTRACT(EPOCH FROM (timestamp - prev_timestamp)) AS iet_seconds\n",
    "      FROM ordered_events\n",
    "      WHERE prev_timestamp IS NOT NULL\n",
    "    )\n",
    "    SELECT \n",
    "      timestamp,\n",
    "      iet_seconds,\n",
    "      AVG(iet_seconds) OVER () AS mean_iet,\n",
    "      STDDEV(iet_seconds) OVER () AS stddev_iet\n",
    "    FROM inter_event_times;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21cf4aff-3975-4984-a2e1-e80da9a03e18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timestamps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_anomaly\u001b[39m\u001b[38;5;124m'\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m anomalies \u001b[38;5;241m=\u001b[39m inter_event_time_analysis(timestamps)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInter-event Time Anomalies:\u001b[39m\u001b[38;5;124m\"\u001b[39m, anomalies)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'timestamps' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def inter_event_time_analysis(timestamps, threshold=2):\n",
    "    df = pd.DataFrame({'timestamp': pd.to_datetime(timestamps)}).sort_values('timestamp')\n",
    "    df['iet'] = df['timestamp'].diff().dt.total_seconds()\n",
    "    \n",
    "    mean_iet = df['iet'].mean()\n",
    "    std_iet = df['iet'].std()\n",
    "    \n",
    "    df['is_anomaly'] = df['iet'] < (mean_iet - threshold * std_iet)\n",
    "    \n",
    "    return df[df['is_anomaly']]['timestamp'].tolist()\n",
    "\n",
    "# Usage\n",
    "anomalies = inter_event_time_analysis(timestamps)\n",
    "print(\"Inter-event Time Anomalies:\", anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc1c024-1de2-4f38-9f4e-7e4101ea4f21",
   "metadata": {},
   "source": [
    "__Sliding Window Event Count:__\n",
    "\n",
    "    WITH event_counts AS (\n",
    "      SELECT \n",
    "        e1.timestamp,\n",
    "        COUNT(*) AS event_count\n",
    "      FROM events e1\n",
    "      JOIN events e2 ON e2.timestamp BETWEEN e1.timestamp - INTERVAL '7 days' AND e1.timestamp\n",
    "      GROUP BY e1.timestamp\n",
    "    )\n",
    "    SELECT \n",
    "      timestamp,\n",
    "      event_count,\n",
    "      AVG(event_count) OVER () AS mean_count,\n",
    "      STDDEV(event_count) OVER () AS stddev_count\n",
    "    FROM event_counts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b2c90-1fe7-4227-8442-53c68be137d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2537847-2790-4ecf-ad65-955c08ee675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def inter_event_time_analysis(timestamps, threshold=2):\n",
    "    df = pd.DataFrame({'timestamp': pd.to_datetime(timestamps)}).sort_values('timestamp')\n",
    "    df['iet'] = df['timestamp'].diff().dt.total_seconds()\n",
    "    \n",
    "    mean_iet = df['iet'].mean()\n",
    "    std_iet = df['iet'].std()\n",
    "    \n",
    "    df['is_anomaly'] = df['iet'] < (mean_iet - threshold * std_iet)\n",
    "    \n",
    "    return df[df['is_anomaly']]['timestamp'].tolist()\n",
    "\n",
    "# Usage\n",
    "anomalies = inter_event_time_analysis(timestamps)\n",
    "print(\"Inter-event Time Anomalies:\", anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef7079-ae16-496e-a68c-57e6135ba161",
   "metadata": {},
   "source": [
    "__Sliding Window Event Count:__\n",
    "\n",
    "    WITH event_counts AS (\n",
    "      SELECT \n",
    "        e1.timestamp,\n",
    "        COUNT(*) AS event_count\n",
    "      FROM events e1\n",
    "      JOIN events e2 ON e2.timestamp BETWEEN e1.timestamp - INTERVAL '7 days' AND e1.timestamp\n",
    "      GROUP BY e1.timestamp\n",
    "    )\n",
    "    SELECT \n",
    "      timestamp,\n",
    "      event_count,\n",
    "      AVG(event_count) OVER () AS mean_count,\n",
    "      STDDEV(event_count) OVER () AS stddev_count\n",
    "    FROM event_counts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52ced4-fcf2-43d6-bef8-af4005d534ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def sliding_window_count(timestamps, window_size=7, threshold=2):\n",
    "    df = pd.DataFrame({'timestamp': pd.to_datetime(timestamps)}).sort_values('timestamp')\n",
    "    window = pd.Timedelta(days=window_size)\n",
    "    \n",
    "    df['count'] = df.apply(lambda row: sum((row['timestamp'] - window <= ts <= row['timestamp']) for ts in df['timestamp']), axis=1)\n",
    "    \n",
    "    mean_count = df['count'].mean()\n",
    "    std_count = df['count'].std()\n",
    "    \n",
    "    df['is_anomaly'] = df['count'] > (mean_count + threshold * std_count)\n",
    "    \n",
    "    return df[df['is_anomaly']]['timestamp'].tolist()\n",
    "\n",
    "# Usage\n",
    "anomalies = sliding_window_count(timestamps)\n",
    "print(\"Sliding Window Count Anomalies:\", anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc7309-4bfc-42aa-a82b-b710542e2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __Kernel Density Estimation:__\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "def kde_analysis(timestamps, bandwidth=7, threshold=2):\n",
    "    df = pd.DataFrame({'timestamp': pd.to_datetime(timestamps)}).sort_values('timestamp')\n",
    "    X = df['timestamp'].astype(int).values.reshape(-1, 1)\n",
    "    \n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth * 86400)  # convert days to seconds\n",
    "    kde.fit(X)\n",
    "    \n",
    "    log_dens = kde.score_samples(X)\n",
    "    \n",
    "    mean_log_dens = np.mean(log_dens)\n",
    "    std_log_dens = np.std(log_dens)\n",
    "    \n",
    "    df['is_anomaly'] = log_dens < (mean_log_dens - threshold * std_log_dens)\n",
    "    \n",
    "    return df[df['is_anomaly']]['timestamp'].tolist()\n",
    "\n",
    "# Usage\n",
    "anomalies = kde_analysis(timestamps)\n",
    "print(\"KDE Anomalies:\", anomalies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e082d4e-409b-4560-9006-9c54c483d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizaiton\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "def inter_event_time_analysis(dates, threshold=2):\n",
    "    df = pd.DataFrame({'date': pd.to_datetime(dates)}).sort_values('date')\n",
    "    df['iet'] = df['date'].diff().dt.days\n",
    "    \n",
    "    mean_iet = df['iet'].mean()\n",
    "    std_iet = df['iet'].std()\n",
    "    \n",
    "    df['is_anomaly'] = df['iet'] < (mean_iet - threshold * std_iet)\n",
    "    \n",
    "    return df[df['is_anomaly']]['date'].tolist()\n",
    "\n",
    "def sliding_window_count(dates, window_size=7, threshold=2):\n",
    "    df = pd.DataFrame({'date': pd.to_datetime(dates)}).sort_values('date')\n",
    "    \n",
    "    df['count'] = df.apply(lambda row: sum((row['date'] - pd.Timedelta(days=window_size) <= d <= row['date']) for d in df['date']), axis=1)\n",
    "    \n",
    "    mean_count = df['count'].mean()\n",
    "    std_count = df['count'].std()\n",
    "    \n",
    "    df['is_anomaly'] = df['count'] > (mean_count + threshold * std_count)\n",
    "    \n",
    "    return df[df['is_anomaly']]['date'].tolist()\n",
    "\n",
    "def kde_analysis(dates, bandwidth=7, threshold=2):\n",
    "    df = pd.DataFrame({'date': pd.to_datetime(dates)}).sort_values('date')\n",
    "    X = df['date'].astype(int).values.reshape(-1, 1) // 10**9 // 86400  # convert to days since epoch\n",
    "    \n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth)\n",
    "    kde.fit(X)\n",
    "    \n",
    "    log_dens = kde.score_samples(X)\n",
    "    \n",
    "    mean_log_dens = np.mean(log_dens)\n",
    "    std_log_dens = np.std(log_dens)\n",
    "    \n",
    "    df['is_anomaly'] = log_dens < (mean_log_dens - threshold * std_log_dens)\n",
    "    \n",
    "    return df[df['is_anomaly']]['date'].tolist()\n",
    "\n",
    "def visualize_anomalies(dates, iet_anomalies, swc_anomalies, kde_anomalies):\n",
    "    dates = pd.to_datetime(dates)\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 15), sharex=True)\n",
    "    \n",
    "    # Common x-axis settings\n",
    "    plt.xlabel('Date')\n",
    "    plt.xlim(dates.min(), dates.max())\n",
    "    \n",
    "    # Inter-event Time Analysis\n",
    "    ax1.scatter(dates, [1]*len(dates), alpha=0.5, label='Events')\n",
    "    ax1.scatter(iet_anomalies, [1]*len(iet_anomalies), color='red', s=100, marker='*', label='IET Anomalies')\n",
    "    ax1.set_title('Inter-event Time Analysis')\n",
    "    ax1.legend()\n",
    "    ax1.set_yticks([])\n",
    "    \n",
    "    # Sliding Window Count\n",
    "    ax2.scatter(dates, [1]*len(dates), alpha=0.5, label='Events')\n",
    "    ax2.scatter(swc_anomalies, [1]*len(swc_anomalies), color='green', s=100, marker='*', label='SWC Anomalies')\n",
    "    ax2.set_title('Sliding Window Count')\n",
    "    ax2.legend()\n",
    "    ax2.set_yticks([])\n",
    "    \n",
    "    # Kernel Density Estimation\n",
    "    ax3.scatter(dates, [1]*len(dates), alpha=0.5, label='Events')\n",
    "    ax3.scatter(kde_anomalies, [1]*len(kde_anomalies), color='orange', s=100, marker='*', label='KDE Anomalies')\n",
    "    ax3.set_title('Kernel Density Estimation')\n",
    "    ax3.legend()\n",
    "    ax3.set_yticks([])\n",
    "    \n",
    "    # Format x-axis\n",
    "    for ax in [ax1, ax2, ax3]:\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# Replace this with your actual dates\n",
    "dates = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')\n",
    "dates = dates[np.random.rand(len(dates)) > 0.7]  # Randomly select about 30% of the days\n",
    "\n",
    "iet_anomalies = inter_event_time_analysis(dates)\n",
    "swc_anomalies = sliding_window_count(dates)\n",
    "kde_anomalies = kde_analysis(dates)\n",
    "\n",
    "visualize_anomalies(dates, iet_anomalies, swc_anomalies, kde_anomalies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
