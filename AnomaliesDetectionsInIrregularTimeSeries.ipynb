{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6cb05f-77ab-4ed9-a8bc-81f751501994",
   "metadata": {},
   "source": [
    "#### detection of the surging of events in an irregular time series\n",
    "\n",
    "__Inter-event Time Analysis:__\n",
    "\n",
    "Calculates the time between consecutive events.\n",
    "Flags events where the inter-event time is significantly shorter than average.\n",
    "\n",
    "\n",
    "__Sliding Window Event Count:__\n",
    "\n",
    "Counts events within a sliding time window.\n",
    "Flags time points where the event count is significantly higher than average.\n",
    "\n",
    "\n",
    "__Kernel Density Estimation:__\n",
    "\n",
    "Uses KDE to estimate the density of events over time.\n",
    "Flags events in regions of unusually high density."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce25d5b-3366-4213-9d56-ef05dc9fb8de",
   "metadata": {},
   "source": [
    "__Inter-event Time Analysis:__\n",
    "\n",
    "    WITH ordered_events AS (\n",
    "      SELECT \n",
    "        timestamp,\n",
    "        LAG(timestamp) OVER (ORDER BY timestamp) AS prev_timestamp\n",
    "      FROM events\n",
    "    ),\n",
    "    inter_event_times AS (\n",
    "      SELECT \n",
    "        timestamp,\n",
    "        EXTRACT(EPOCH FROM (timestamp - prev_timestamp)) AS iet_seconds\n",
    "      FROM ordered_events\n",
    "      WHERE prev_timestamp IS NOT NULL\n",
    "    )\n",
    "    SELECT \n",
    "      timestamp,\n",
    "      iet_seconds,\n",
    "      AVG(iet_seconds) OVER () AS mean_iet,\n",
    "      STDDEV(iet_seconds) OVER () AS stddev_iet\n",
    "    FROM inter_event_times;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21cf4aff-3975-4984-a2e1-e80da9a03e18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timestamps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_anomaly\u001b[39m\u001b[38;5;124m'\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m anomalies \u001b[38;5;241m=\u001b[39m inter_event_time_analysis(timestamps)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInter-event Time Anomalies:\u001b[39m\u001b[38;5;124m\"\u001b[39m, anomalies)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'timestamps' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def inter_event_time_analysis(timestamps, threshold=2):\n",
    "    df = pd.DataFrame({'timestamp': pd.to_datetime(timestamps)}).sort_values('timestamp')\n",
    "    df['iet'] = df['timestamp'].diff().dt.total_seconds()\n",
    "    \n",
    "    mean_iet = df['iet'].mean()\n",
    "    std_iet = df['iet'].std()\n",
    "    \n",
    "    df['is_anomaly'] = df['iet'] < (mean_iet - threshold * std_iet)\n",
    "    \n",
    "    return df[df['is_anomaly']]['timestamp'].tolist()\n",
    "\n",
    "# Usage\n",
    "anomalies = inter_event_time_analysis(timestamps)\n",
    "print(\"Inter-event Time Anomalies:\", anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc1c024-1de2-4f38-9f4e-7e4101ea4f21",
   "metadata": {},
   "source": [
    "__Sliding Window Event Count:__\n",
    "\n",
    "    WITH event_counts AS (\n",
    "      SELECT \n",
    "        e1.timestamp,\n",
    "        COUNT(*) AS event_count\n",
    "      FROM events e1\n",
    "      JOIN events e2 ON e2.timestamp BETWEEN e1.timestamp - INTERVAL '7 days' AND e1.timestamp\n",
    "      GROUP BY e1.timestamp\n",
    "    )\n",
    "    SELECT \n",
    "      timestamp,\n",
    "      event_count,\n",
    "      AVG(event_count) OVER () AS mean_count,\n",
    "      STDDEV(event_count) OVER () AS stddev_count\n",
    "    FROM event_counts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b2c90-1fe7-4227-8442-53c68be137d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2537847-2790-4ecf-ad65-955c08ee675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def inter_event_time_analysis(timestamps, threshold=2):\n",
    "    df = pd.DataFrame({'timestamp': pd.to_datetime(timestamps)}).sort_values('timestamp')\n",
    "    df['iet'] = df['timestamp'].diff().dt.total_seconds()\n",
    "    \n",
    "    mean_iet = df['iet'].mean()\n",
    "    std_iet = df['iet'].std()\n",
    "    \n",
    "    df['is_anomaly'] = df['iet'] < (mean_iet - threshold * std_iet)\n",
    "    \n",
    "    return df[df['is_anomaly']]['timestamp'].tolist()\n",
    "\n",
    "# Usage\n",
    "anomalies = inter_event_time_analysis(timestamps)\n",
    "print(\"Inter-event Time Anomalies:\", anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef7079-ae16-496e-a68c-57e6135ba161",
   "metadata": {},
   "source": [
    "__Sliding Window Event Count:__\n",
    "\n",
    "    WITH event_counts AS (\n",
    "      SELECT \n",
    "        e1.timestamp,\n",
    "        COUNT(*) AS event_count\n",
    "      FROM events e1\n",
    "      JOIN events e2 ON e2.timestamp BETWEEN e1.timestamp - INTERVAL '7 days' AND e1.timestamp\n",
    "      GROUP BY e1.timestamp\n",
    "    )\n",
    "    SELECT \n",
    "      timestamp,\n",
    "      event_count,\n",
    "      AVG(event_count) OVER () AS mean_count,\n",
    "      STDDEV(event_count) OVER () AS stddev_count\n",
    "    FROM event_counts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52ced4-fcf2-43d6-bef8-af4005d534ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def sliding_window_count(timestamps, window_size=7, threshold=2):\n",
    "    df = pd.DataFrame({'timestamp': pd.to_datetime(timestamps)}).sort_values('timestamp')\n",
    "    window = pd.Timedelta(days=window_size)\n",
    "    \n",
    "    df['count'] = df.apply(lambda row: sum((row['timestamp'] - window <= ts <= row['timestamp']) for ts in df['timestamp']), axis=1)\n",
    "    \n",
    "    mean_count = df['count'].mean()\n",
    "    std_count = df['count'].std()\n",
    "    \n",
    "    df['is_anomaly'] = df['count'] > (mean_count + threshold * std_count)\n",
    "    \n",
    "    return df[df['is_anomaly']]['timestamp'].tolist()\n",
    "\n",
    "# Usage\n",
    "anomalies = sliding_window_count(timestamps)\n",
    "print(\"Sliding Window Count Anomalies:\", anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc7309-4bfc-42aa-a82b-b710542e2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __Kernel Density Estimation:__\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "def kde_analysis(timestamps, bandwidth=7, threshold=2):\n",
    "    df = pd.DataFrame({'timestamp': pd.to_datetime(timestamps)}).sort_values('timestamp')\n",
    "    X = df['timestamp'].astype(int).values.reshape(-1, 1)\n",
    "    \n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth * 86400)  # convert days to seconds\n",
    "    kde.fit(X)\n",
    "    \n",
    "    log_dens = kde.score_samples(X)\n",
    "    \n",
    "    mean_log_dens = np.mean(log_dens)\n",
    "    std_log_dens = np.std(log_dens)\n",
    "    \n",
    "    df['is_anomaly'] = log_dens < (mean_log_dens - threshold * std_log_dens)\n",
    "    \n",
    "    return df[df['is_anomaly']]['timestamp'].tolist()\n",
    "\n",
    "# Usage\n",
    "anomalies = kde_analysis(timestamps)\n",
    "print(\"KDE Anomalies:\", anomalies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e082d4e-409b-4560-9006-9c54c483d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizaiton\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "def inter_event_time_analysis(dates, threshold=2):\n",
    "    df = pd.DataFrame({'date': pd.to_datetime(dates)}).sort_values('date')\n",
    "    df['iet'] = df['date'].diff().dt.days\n",
    "    \n",
    "    mean_iet = df['iet'].mean()\n",
    "    std_iet = df['iet'].std()\n",
    "    \n",
    "    df['is_dormant'] = df['iet'] > (mean_iet + threshold * std_iet)\n",
    "    df['is_surge'] = (df['iet'] < (mean_iet - threshold * std_iet)) & (df['iet'] > 0)\n",
    "    \n",
    "    return {\n",
    "        'dormant': df[df['is_dormant']]['date'].tolist(),\n",
    "        'surge': df[df['is_surge']]['date'].tolist()\n",
    "    }\n",
    "\n",
    "def sliding_window_count(dates, window_size=7, threshold=2):\n",
    "    df = pd.DataFrame({'date': pd.to_datetime(dates)}).sort_values('date')\n",
    "    \n",
    "    df['count'] = df.apply(lambda row: sum((row['date'] - pd.Timedelta(days=window_size) <= d <= row['date']) for d in df['date']), axis=1)\n",
    "    \n",
    "    mean_count = df['count'].mean()\n",
    "    std_count = df['count'].std()\n",
    "    \n",
    "    df['is_dormant'] = df['count'] < (mean_count - threshold * std_count)\n",
    "    df['is_surge'] = df['count'] > (mean_count + threshold * std_count)\n",
    "    \n",
    "    return {\n",
    "        'dormant': df[df['is_dormant']]['date'].tolist(),\n",
    "        'surge': df[df['is_surge']]['date'].tolist()\n",
    "    }\n",
    "\n",
    "def kde_analysis(dates, bandwidth=7, threshold=2):\n",
    "    df = pd.DataFrame({'date': pd.to_datetime(dates)}).sort_values('date')\n",
    "    \n",
    "    earliest_date = df['date'].min()\n",
    "    X = (df['date'] - earliest_date).dt.total_seconds().div(86400).values.reshape(-1, 1)\n",
    "    \n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth)\n",
    "    kde.fit(X)\n",
    "    \n",
    "    log_dens = kde.score_samples(X)\n",
    "    \n",
    "    mean_log_dens = np.mean(log_dens)\n",
    "    std_log_dens = np.std(log_dens)\n",
    "    \n",
    "    df['is_dormant'] = log_dens < (mean_log_dens - threshold * std_log_dens)\n",
    "    df['is_surge'] = log_dens > (mean_log_dens + threshold * std_log_dens)\n",
    "    \n",
    "    return {\n",
    "        'dormant': df[df['is_dormant']]['date'].tolist(),\n",
    "        'surge': df[df['is_surge']]['date'].tolist()\n",
    "    }\n",
    "\n",
    "def visualize_anomalies(dates, iet_anomalies, swc_anomalies, kde_anomalies):\n",
    "    dates = pd.to_datetime(dates)\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 15), sharex=True)\n",
    "    \n",
    "    plt.xlabel('Date')\n",
    "    plt.xlim(dates.min(), dates.max())\n",
    "    \n",
    "    # Inter-event Time Analysis\n",
    "    ax1.scatter(dates, [1]*len(dates), alpha=0.5, label='Events')\n",
    "    ax1.scatter(iet_anomalies['dormant'], [1]*len(iet_anomalies['dormant']), color='blue', s=100, marker='v', label='IET Dormant')\n",
    "    ax1.scatter(iet_anomalies['surge'], [1]*len(iet_anomalies['surge']), color='red', s=100, marker='^', label='IET Surge')\n",
    "    ax1.set_title('Inter-event Time Analysis')\n",
    "    ax1.legend()\n",
    "    ax1.set_yticks([])\n",
    "    \n",
    "    # Sliding Window Count\n",
    "    ax2.scatter(dates, [1]*len(dates), alpha=0.5, label='Events')\n",
    "    ax2.scatter(swc_anomalies['dormant'], [1]*len(swc_anomalies['dormant']), color='blue', s=100, marker='v', label='SWC Dormant')\n",
    "    ax2.scatter(swc_anomalies['surge'], [1]*len(swc_anomalies['surge']), color='red', s=100, marker='^', label='SWC Surge')\n",
    "    ax2.set_title('Sliding Window Count')\n",
    "    ax2.legend()\n",
    "    ax2.set_yticks([])\n",
    "    \n",
    "    # Kernel Density Estimation\n",
    "    ax3.scatter(dates, [1]*len(dates), alpha=0.5, label='Events')\n",
    "    ax3.scatter(kde_anomalies['dormant'], [1]*len(kde_anomalies['dormant']), color='blue', s=100, marker='v', label='KDE Dormant')\n",
    "    ax3.scatter(kde_anomalies['surge'], [1]*len(kde_anomalies['surge']), color='red', s=100, marker='^', label='KDE Surge')\n",
    "    ax3.set_title('Kernel Density Estimation')\n",
    "    ax3.legend()\n",
    "    ax3.set_yticks([])\n",
    "    \n",
    "    for ax in [ax1, ax2, ax3]:\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "dates = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')\n",
    "dates = dates[np.random.rand(len(dates)) > 0.7]  # Randomly select about 30% of the days\n",
    "\n",
    "# Add some artificial surges and dormant periods\n",
    "surge_dates = pd.date_range(start='2023-03-01', end='2023-03-10', freq='D')\n",
    "dormant_dates = pd.date_range(start='2023-06-01', end='2023-06-20', freq='3D')\n",
    "dates = dates.union(surge_dates).union(dormant_dates)\n",
    "\n",
    "iet_anomalies = inter_event_time_analysis(dates)\n",
    "swc_anomalies = sliding_window_count(dates)\n",
    "kde_anomalies = kde_analysis(dates)\n",
    "\n",
    "visualize_anomalies(dates, iet_anomalies, swc_anomalies, kde_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc105a54-8dcd-47ca-9bcb-a3b71a7383ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def compute_cumulative_sums_and_detect_surges(dates, window_size=7, surge_threshold=1.5):\n",
    "    # Convert dates to datetime if they're not already\n",
    "    dates = pd.to_datetime(dates)\n",
    "    \n",
    "    # Create a DataFrame with the dates and sort it\n",
    "    df = pd.DataFrame({'date': dates}).sort_values('date')\n",
    "    \n",
    "    # Count events per day\n",
    "    df['event_count'] = 1\n",
    "    df = df.groupby('date').count().reset_index()\n",
    "    \n",
    "    # Ensure we have all dates in the range\n",
    "    date_range = pd.date_range(start=df['date'].min(), end=df['date'].max())\n",
    "    df = df.set_index('date').reindex(date_range, fill_value=0).reset_index()\n",
    "    df = df.rename(columns={'index': 'date'})\n",
    "    \n",
    "    # Compute cumulative sum before each date\n",
    "    df['cum_sum_before'] = df['event_count'].cumsum().shift(1, fill_value=0)\n",
    "    \n",
    "    # Compute cumulative sum including and after each date within the window\n",
    "    df['cum_sum_after'] = df['event_count'].rolling(window=window_size, min_periods=1).sum()\n",
    "    \n",
    "    # Detect surges\n",
    "    df['surge_ratio'] = df['cum_sum_after'] / (df['cum_sum_before'] + 1)  # Add 1 to avoid division by zero\n",
    "    df['is_surge'] = df['surge_ratio'] > surge_threshold\n",
    "    \n",
    "    return df\n",
    "\n",
    "def visualize_surges(df):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10), sharex=True)\n",
    "    \n",
    "    # Plot cumulative sums\n",
    "    ax1.plot(df['date'], df['cum_sum_before'], label='Cumulative Sum Before')\n",
    "    ax1.plot(df['date'], df['cum_sum_after'], label='Cumulative Sum After (7-day window)')\n",
    "    ax1.set_title('Cumulative Sums and Surge Detection')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Highlight surge periods\n",
    "    surge_periods = df[df['is_surge']]\n",
    "    ax1.scatter(surge_periods['date'], surge_periods['cum_sum_after'], \n",
    "                color='red', s=50, zorder=5, label='Surge Detected')\n",
    "    \n",
    "    # Plot surge ratio\n",
    "    ax2.plot(df['date'], df['surge_ratio'], label='Surge Ratio')\n",
    "    ax2.axhline(y=surge_threshold, color='r', linestyle='--', label=f'Surge Threshold ({surge_threshold})')\n",
    "    ax2.set_title('Surge Ratio')\n",
    "    ax2.set_yscale('log')  # Use log scale for better visibility\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Format x-axis\n",
    "    for ax in [ax1, ax2]:\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    \n",
    "    plt.xlabel('Date')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "np.random.seed(42)\n",
    "date_range = pd.date_range(start='2023-01-01', end='2023-12-31')\n",
    "dates = np.random.choice(date_range, size=500)  # 500 random events\n",
    "\n",
    "# Add some artificial surge periods\n",
    "surge_dates = pd.date_range(start='2023-03-01', end='2023-03-10')\n",
    "surge_dates = np.concatenate([surge_dates, pd.date_range(start='2023-07-15', end='2023-07-20')])\n",
    "dates = np.concatenate([dates, surge_dates])\n",
    "\n",
    "# Compute cumulative sums and detect surges\n",
    "surge_threshold = 1.5\n",
    "result_df = compute_cumulative_sums_and_detect_surges(dates, surge_threshold=surge_threshold)\n",
    "\n",
    "# Display the first few rows of the result\n",
    "print(result_df.head(10))\n",
    "\n",
    "# Display surge periods\n",
    "print(\"\\nSurge periods detected:\")\n",
    "print(result_df[result_df['is_surge']][['date', 'surge_ratio']])\n",
    "\n",
    "# Visualize the results\n",
    "visualize_surges(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
